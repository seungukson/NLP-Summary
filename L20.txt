L20. Perceptron.
뉴런의 동작을 흉내낸 기계학습 알고리즘.
최초에는 활성화함수로 step function을 이용함.
노드가 X-feature, edge가 weight. WX값이 0보다 커진다면 신호전달..이라는 형식.

단일 퍼셉트론은 간단.
하지만 비선형문제라면?? 멀티레이어로 ...
weight의 갯수를 늘리는 것으로 해결.. 이것은 x-feature의 갯수를 늘려 차원을늘리는것과
다르다. 선의 갯수를 늘리는것. 그렇다면... 멀티레이어 퍼셉트론에서 노드가 많아지고 다층을 쌓는다는의미?

여러개의 선을 그어서 그 선들 사이의 논리연산을 하겠다는 의미!!

이게 곧 뉴럴네트워크로 발전

Neural Networks.
그런데, 뉴럴네트워크가 다층으로 갈수록.. step function과 sigmoid함수의 한계가 발생..
결과값이 무조건 0과 1사이므로 결국 0으로 수렴한다... 결과가 제대로 나올수가 없음..
그래서 ReLU를 이용... 0.5이하의 수는 0, 그 이상은 y=x로 만들어서 값을 어느정도 선에서 유지하게함.

